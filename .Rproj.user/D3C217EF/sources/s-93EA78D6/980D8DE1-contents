# dart_functions
# Description : functions to scrape DART pages

# 1. dart_url ------------------------------------------------------------------
#' Find url corresponding to rcp and dcm info
#'
#' @importFrom magrittr %>%
#' @import dplyr
#' @export
dart_url <- function(rcp, dcm) {
  # Provide the correct url address of the report corresponding to the rcp & dcm
  # If dcm is not provided, it uses only the rcp

  if (missing(dcm)) {
    url_original <- paste0("http://dart.fss.or.kr/dsaf001/main.do?rcpNo=", rcp)
  } else {
    url_original <- paste0("http://dart.fss.or.kr/dsaf001/main.do?rcpNo=", rcp,
                           "&dcmNo=", dcm)
  }
  return(url_original)
}

# 2. cut_text ------------------------------------------------------------------
#' @export
cut_text <- function(txt_original, start_text, end_text) {
  # This function cuts the txt_original to the one between start_text and end_text
  # Intended use : for the case where start_text and end_text are unique

  # In case of multiple occurences, it uses the first occurence of start_text
  # and the first occurence of end_text that comes AFTER the start_text

  # for (txt in c(start_text, end_text)) {
  #   if (str_locate_all(txt_original, txt)[[1]] %>% nrow > 1) {
  #     print(paste0(
  #       "WARNING : multiple occurences of \"", txt, "\" in the main text"))
  #   }
  # }

  loc_west <-
    str_locate_all(txt_original, start_text)[[1]][1,2] %>%
    as.numeric

  loc_center <-
    str_locate_all(txt_original, end_text) %>%
    unlist %>% as.data.frame() %>% filter(. > loc_west) %>% min %>% as.numeric

  txt_toc <- substr(txt_original, (loc_west + 1), (loc_center - 1))

  return(txt_toc)
}

# 2.1. cut_text_ ---------------------------------------------------------------
#' @export
cut_text_ <- function(txt_original, start_text, end_text) {
  # Similar function as cut_text, but with two key differences :
  # 1) start_text == "start" or end_text == "end" => cuts from start/to the end
  # 2) If either start_text or end_text not there (and are not "start" or "end")
  #    then gives back txt_original unchaged.

  # Explanation that pertains to cut_text :
  # This function cuts the txt_original to the one between start_text and end_text
  # Intended use : for the case where start_text and end_text are unique

  # In case of multiple occurences, it uses the first occurence of start_text
  # and the first occurence of end_text that comes AFTER the start_text


  if (start_text != "start" & end_text != "end") {
    if (grepl(start_text, txt_original, fixed= TRUE) &
        grepl(end_text, txt_original, fixed= TRUE)) {
      loc_west <-
        str_locate_all(txt_original, start_text)[[1]][1,2] %>%
        as.numeric

      loc_center <-
        str_locate_all(txt_original, end_text) %>%
        unlist %>% as.data.frame() %>% filter(. > loc_west) %>% min %>% as.numeric

      txt_toc <- substr(txt_original, (loc_west + 1), (loc_center - 1))
    } else {
      txt_toc <- txt_original
    }
  } else if (start_text == "start") {
    if (grepl(end_text, txt_original, fixed = TRUE)) {
      loc_center <-
        str_locate_all(txt_original, end_text) %>%
        unlist %>% as.data.frame() %>% min %>% as.numeric

      txt_toc <- substr(txt_original, 1, (loc_center - 1))
    } else {
      txt_toc <- txt_original
    }
  } else if (end_text == "end") {
    if (grepl(start_text, txt_original, fixed = TRUE)) {
      loc_west <-
        str_locate_all(txt_original, start_text)[[1]][1,2] %>%
        as.numeric

      txt_toc <- substr(txt_original, (loc_west + 1), str_length(txt_original))
    } else {
      txt_toc <- txt_original
    }
  }
  return(txt_toc)
}

# 3. toc_frame -----------------------------------------------------------------
#' @export
toc_frame <- function(firmcode, url_original, txt_original) {
  # This function creates a dataframe containing url information of
  # DART reports' table of contents

  # 1) First make sure that txt_original is legit, by checking for the panels
  if (grepl("west-panel", txt_original) & grepl("center-panel", txt_original)) {

    # 2) Find the area of the txt_original to focus on
    txt_toc <- cut_text(txt_original, "west-panel", "center-panel")
    ## Since reports are divided into west-panel, center-panel and east-panel
    ## and table-of-contents are in the west-panel, we focus there

    # 3) Get all text descriptions of the table of contents
    toc <-
      str_match_all(txt_toc,
                    "\n\t\t\ttext: \\\" *(.*?) *\",\n\t\t\tid")[[1]][,2] %>%
      as.character

    # 4) create toc_full to make the text descriptions unique
    #   (so that we can search for it later, and discern url of each one)
    toc_full <-
      str_match_all(txt_toc,
                    "\n\t\t\ttext: \\\" *(.*?) *\",\n\t\t\tid")[[1]][,1] %>%
      as.character

    # 5) Create toc_frame first, then fill it up with V1-V10 columns
    toc_frame <-
      data.frame(title = toc, toc_full = toc_full, stringsAsFactors = FALSE) %>%
      bind_cols(data.frame(matrix("", nrow = length(toc), ncol = 10),
                           stringsAsFactors = FALSE) %>%
                  set_colnames(paste0("V", 1:10)))

    # 6) Take the url information and fill up toc_frame
    for (i in 1:nrow(toc_frame)) {
      txt_toc_temp <-
        substr(txt_toc,
               str_locate_all(txt_toc,
                              # stringr::coll : fixed 와 같은 기능을 수행함.
                              stringr::coll(toc_frame$toc_full[i]))[[1]][1,2],
               str_length(txt_toc))

      toc_frame[i, paste0("V", 1:10)] <-
        read.table(text = str_match_all(txt_toc_temp,
                                        "viewDoc\\(\\'([a-z0-9.', ]+)")[[1]][1,2],
                   fill = T, stringsAsFactors = FALSE) %>%
        as.data.frame(stringsAsFactors = FALSE)
    }
    toc_frame %<>% mutate(V1 = gsub("',", "", V1))
  } else {
    # 7) If the txt_original isn't legit, give back an empty dataframe
    V_frame <-
      data.frame(matrix(ncol = 10, nrow = 0)) %>%
      mutate_all(as.character) %>%
      set_colnames(paste0("V", c(1:10)))

    toc_frame <-
      data.frame(title=character(),
                 toc_full=character(),
                 stringsAsFactors=FALSE) %>%
      bind_cols(V_frame)
  }

  # 8) Create 'title_simple' by eliminating whitespaces
  toc_frame <-
    toc_frame %>%
    mutate(title_simple = gsub("\\s+", "", title) %>% gsub("&nbsp;", "", .))

  # 9) Create 'url', eliminate unused columns then change column names
  toc_frame %<>% mutate(
    firmcode = firmcode,
    url_original = url_original,
    url = paste0("http://dart.fss.or.kr/report/viewer.do?",
                 "rcpNo=", V1, "&dcmNo=",  V2, "&eleId=",  V4, "&offset=", V6,
                 "&length=", V8, "&dtd=", V10)) %>%
    select(firmcode, title, title_simple, toc_full, V1, V2, V4, V6, V8, V10, url, url_original) %>%
    set_colnames(c("firmcode", "title", "title_simple", "toc_full", "rcp",
                   "dcm", "eleId", "offset", "length", "dtd", "url", "url_original"))

  return(toc_frame)
}


# 4. toc_frame_select ----------------------------------------------------------
#' @encoding UTF-8
#' @export
toc_frame_select <- function(firmcode, df, name_wd) {
  if (Sys.getlocale("LC_COLLATE") != "Korean_Korea.949") {
    Sys.setlocale("LC_ALL", "korean")
  }
  # Find those that include "주석" but excludes "연결"
  target_tf <-
    grepl("^(?=.*주석)(?!.*연결)", df$title_simple, perl = TRUE)

  if (sum(target_tf) > 0) {
    target_frame <- df[target_tf,]
  } else {
    target_frame <- df[0,]
  }

  # Save information on file locations
  target_frame %<>%
    mutate(
      fileloc =
        paste(firmcode, rcp, dcm, eleId, offset, length, dtd, sep = "_"),
      fileloc_full =
        paste0(paste0("./data/raw/DART/html_", name_wd, "/"),
               paste(firmcode, rcp, dcm, eleId, offset, length, dtd,
                     sep = "_"), ".html")) %>%
    select(firmcode, title, title_simple, toc_full, rcp,
            dcm, eleId, offset, length, dtd, url, url_original,
            fileloc, fileloc_full)
  if (Sys.getlocale("LC_COLLATE") != "English_United States.1252") {
    Sys.setlocale("LC_ALL", "English_United States.1252")
  }
  return(target_frame)
}

# 5. dart_save -----------------------------------------------------------------
#' @export
dart_save <- function(df) {
  # Save xml files
  for (i in 1:nrow(df)) {
    write_xml(read_html(df$url[i]),
              file = df$fileloc_full[i])
  }
}

# 6. dcm_tf --------------------------------------------------------------------
#' @encoding UTF-8
#' @export
dcm_tf <- function(txt_original) {
  # This function discerns if 'attached documents' part of DART reports
  # should be used / recorded, then returns TRUE/FALSE

  # Make sure that the function can read Korean
  if (Sys.getlocale("LC_COLLATE") != "Korean_Korea.949") {
    Sys.setlocale("LC_ALL", "korean")
  }

  txt_dcm_titles <- cut_text(txt_original, "첨부선택+", "function")

  dcm_titles_frame <-
    strsplit(gsub("[0-9]|\\+|\n|\t|\\.", "", txt_dcm_titles), "\\s+") %>%
    unlist %>%
    as.data.frame(stringsAsFactors = FALSE) %>%
    set_colnames("title") %>%
    filter(title != "")
  dcm_titles <- dcm_titles_frame$title %>% as.character

  title_exist <-
    grepl("^감사보고서$|^사업보고서$|^반기검토보고서$",
          dcm_titles)

  # Return to English
  if (Sys.getlocale("LC_COLLATE") != "English_United States.1252") {
    Sys.setlocale("LC_ALL", "English_United States.1252")
  }
  if (sum(title_exist) > 0) {return(TRUE)} else {return(FALSE)}
}

# 7. dcm_frame -----------------------------------------------------------------
#' @export
dcm_frame <- function(firmcode, url_original, browsermode) {

  # This was the original code, but we are not using RSelenium anymore
  # Use RSelenium to find the pagesource with dcmNo of supplementary documents
  # remDr$navigate(url_original)
  # temp_pagesource <- remDr$getPageSource()[[1]] %>% as.character

  # Use webdriver to find the pagesource with dcmNo of supplementary documents
  if (browsermode == "webdriver" | missing(browsermode)) {
    ses$go(url_original)
    temp_pagesource <- ses$getSource()
  } else if (browsermode == "RSelenium") {
    remDr$navigate(url_original)
    temp_pagesource <- remDr$getPageSource()
  }

  # Find the title, rcp and dcmNo of the supplementary documents
  ## 1) First find the chunk of string containing the info
  dcm_string <-
    str_extract_all(temp_pagesource,
                    paste0("option value=\"rcpNo=",
                           "(\\d{14})",
                           "&amp;dcmNo=",
                           "[0-9]+")) %>% unlist

  # Check if there is ANY 첨부파일, then continue
  if (length(dcm_string) > 0) {
    ## 2) Find the rcps
    dcm_rcp <-
      str_extract_all(dcm_string,
                      paste0("(?<=option value=\"rcpNo=)",
                             "\\d{14}",
                             "(?=&amp;dcmNo=)")) %>% unlist
    ## 3) Find the dcmNo
    dcm_vector <-
      dcm_string %>%
      str_extract_all("\\d+$") %>% unlist #%>% as.character  ######

    ## 4) Find the titles of the supplementary documents (reports)
    dcm_title <- c()
    for (i in 1:length(dcm_vector)) {
      dcm_title <-
        c(dcm_title,
          str_match(temp_pagesource,
                    paste0("option value=\"rcpNo=", dcm_rcp[i],
                           "&amp;dcmNo=", dcm_vector[i],
                           "[\">\n\t0-9.\\s&nbsp;]+",
                           "(.*?)[\n\t0-9.\\s]+"))[1,2])
    }

    temp_frame <-
      data.frame(dcm_title = dcm_title,
                 rcp = dcm_rcp,
                 dcm = dcm_vector %>% as.character,
                 url_original = url_original, stringsAsFactors = FALSE)
  } else {
    temp_frame <-
      data.frame(dcm_title = character(),
                 rcp = character(),
                 dcm = character(),
                 url_original = character(), stringsAsFactors = FALSE)
  }

  temp_frame %<>%
    mutate(
      firmcode = firmcode,
      url = paste0("http://dart.fss.or.kr/dsaf001/main.do?rcpNo=", rcp,
                   "&dcmNo=", dcm),
      rcp_original = gsub("http://dart.fss.or.kr/dsaf001/main.do?rcpNo=",
                          "", url_original, fixed = TRUE)) %>%
    select(firmcode, dcm_title, rcp, dcm, url, rcp_original, url_original)

  return(temp_frame)
}

# 8. dcm_frame_select ----------------------------------------------------------
#' @encoding UTF-8
#' @export
dcm_frame_select <- function(firmcode, df, name_wd) {
  # Make sure that the function can read Korean
  if (Sys.getlocale("LC_COLLATE") != "Korean_Korea.949") {
    Sys.setlocale("LC_ALL", "korean")
  }

  # Among dcm_frame, select only the following three categories
  df %<>%
    filter(grepl("^감사보고서$|^사업보고서$|^반기검토보고서$", dcm_title)) %>%
    mutate(rpt = ifelse(dcm_title == "감사보고서", "Fyear",
                        ifelse(dcm_title == "사업보고서", "Ayear", "Ahalf")),
           # firmcode = firmcode,
           fileloc = paste(firmcode, rcp_original, rpt, rcp, dcm, sep = "_"),
           fileloc_full =
             paste0(paste0("./data/raw/DART/html_dcm_", name_wd, "/"),
                    paste(firmcode, rcp_original, rpt, rcp, dcm, sep = "_"),    # 근데 이렇게하면 첨부파일을 긁어낼 때 원래의 rcp 랑 연관이 되나?
                    ".html")) %>%
    select(firmcode, rcp, dcm, dcm_title, rpt, url, rcp_original, url_original,
            fileloc, fileloc_full)

  # Return to English
  if (Sys.getlocale("LC_COLLATE") != "English_United States.1252") {
    Sys.setlocale("LC_ALL", "English_United States.1252")
  }
  return(df)
}
